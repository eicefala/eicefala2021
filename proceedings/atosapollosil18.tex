\chapter{Radial Basis Function Artificial Neural Network for Automatic Identification of Interlanguage Transfer Phenomena}\label{ch:atosapollosil18}
\chapterauthor[1]{Atos Apollo Silva Borges}
\chapterauthor[1]{BrunoFerreira de Sousa}
\chapterauthor[2]{Aratuza Rodrigues Silva Rocha}
\chapterauthor[3]{Wilson Júnior de Araújo Carvalho}
\chapterauthor[1]{Fábio Rocha Barbosa}
\chapterauthor[4]{Ronaldo Mangueira Lima Júnior}
\begin{affils}
\chapteraffil[1]{Federal University of Piauí}
\chapteraffil[2]{Faculdade Afonso Mafrense}
\chapteraffil[3]{State University of Ceará}
\chapteraffil[4]{Federal University of Ceará}
\end{affils}

\begin{abstract}
In the recent decades, especially for non-English speaking
countries, the modern and more connected world has increased the urgency in
learning a second language. Among the obstacles for beginners acquiring a new
language are the grapho-phonic-phonological transfer phenomena between the two
language systems, which may undermine their ability to communicate in the
target language. The present work proposes a seed for an intelligent software
designed to help language learners by providing automatic identification of
transfer phenomena produced during their reading process.The algorithm is
centered on a Radial Basis Function Artificial Neural Network (RBF-ANN) trained
to automatically identify transfer processes between Brazilian Portuguese and
English as ForeignLanguage. Five transfer processes already known in the
literature were chosen to demonstrate the concept; however, as an initial
approach, the audio samples used for training the algorithm weresynthetically
generated by the Google Translate™ TTS system. To train the RBF-ANN algorithm
we used the $\textit{f}_0$ mean and the mean of the first two Formant
Frequencies as signal descriptors. The results presented a promising
perspective for the development of a new computer-assisted pronunciation
training software (CAPT) with accessible computational resources for Brazilian
students and language institutes.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
During the learning of a new language, a process called interphonology is
manifested. Interphonology is characterized as the creation of a linguistic
system different from both the foreign language (L2) and native language (L1),
but presenting characteristics from both languages simultaneously
\citep{rocha_os_2012}. The students in the processes of acquiring fluency on
the second language transfer some of their knowledge of the L1 to the new
language due to the already established structure of the L1. This phenomenon,
which may be manifested during speech or oral reading, it is called
grapho-phonic-phonological knowledge transfer \citep{zimmer_producao_2006}.
The term grapho-phonic-phonological contemplates not only the transference of
phonetic-phonological knowledge but also the transference of the
grapheme-phoneme relationship of one language to the other, in the case of
this work, Brazilian Portuguese (BP) as L1 to the English as Foreign Language
(EFL), the L2. When the learner finds an unknown structure in the foreign
language, it uses strategies to adapt L2 to a structure already known in L1.

Transfer phenomena between Portuguese as L1 and English L2 produced by
Brazilian learners are well documented in the literature
\citep{silveira_efeito_2021}. However, the identification and classification of
these processes are made mainly through transcriptions, a slow and laborious
process done by specialized linguists. However, there is a shortage of works
aimed at recognizing these processes in an automated way. Most studies carry
this task as a general mispronunciation identification, comparing the input
speech with a pre-recorded dataset of pronunciations, not taking advantage of
the nature of each phenomenon. Most studies treat mispronunciation as a random
process, not having any patter or regularity to be explored. Only two works
were found proposing forms of automatic identification that take the nature of
the phenomena as an important part of the recognition. The first was a
categorization of BP speakers by a Self-Organizing Map (SOM) regarding the
transfer of stress patterns between BP-L1 and English-L2
\citep{silva_som-based_2011}. The second also aimed to identify transfer
processes from BP to English-L2 of Brazilian students using a Multi-Layer
Perceptron (MLP) neural network \citep{rocha_identificacao_2017}. The rapid
identification of these phenomena would be of great value for software doing
proficiency placement testsand could be used in language schools, distance
education, computer-assisted pronunciation training (CAPT), researchers, and
inclusion of neurodivergent people \citep{grund_2020}.

Therefore, this work proposes a seed for an intelligent software designed to
help language learners by providing automatic identification of transfer
phenomena produced during their reading process. The algorithm is centered on a
Radial Basis Function Artificial Neural Network (RBF-ANN) trained to
automatically identify transfer processes known in the literature of BP
transfer to English-L2. The details of the algorithm are described on the RBF
Neural Network section. Five transfer processes were chosen to demonstrate the
concept and are described on the Acoustic data generation section; however, as
an initial approach, the audio samples used for training the algorithm were
synthetically generated by the Google Translate™ Text-To-Speech system. We
assumed the hypothesis that even simple architectures of Artificial Neural
Network, such as Radial Basis Function ANNs, are able to correctly identify the
chosen transfer phenomena between Brazilian Portuguese-L1 to English-L2.

\section{Acoustic data generation}
The corpus of this study was constructed using the Corpus of Contemporary
American English (COCA), an online and open-access corpus of English with a
large variety of written and spoken words. Non-words were also incorporated to
the study, all generated by the authors modifying existing words but still
obeying English phonological patterns. As the pronunciations in this work
should besynthetically generated, there were only two recordings for each word,
one with the effects of the transfer phenomenon, as if pronounced by a
Brazilian learner, and the other without it, as if pronounced by an English
native speaker. A varied quantity of words must be used to be able to reach
statistical significance. For this reason, a total of 508 words were used,
generating a totalof 1016 recordings.

Five widely known transfer phenomena were chosen to be collected in the Google
Translate™ TTS system. These phenomena are well documented and commonly found
in the pronunciation of Brazilian beginning learners of English.

The first phenomenon investigated was the deletion of initial [h] in words
beginning with $<$h$>$ (henceforth, H-deletion), which corresponds to the
deletion of the glottal fricative [h] at thebeginning of a word. As initial
$<$h$>$ has no corresponding sound in Portuguese, a Brazilian learner might
produce [i] and [u] in the beginning of ‘hilarious’ and ‘humorist’,
respectively.

The second phenomenon was the deletion of initial [h] with a change of [aj] to
[i] in words beginning with $<$hy$>$ (henceforth, HY-i). As in the previous
process, the deletion of [h] occurs due to the absence of a sound corresponding
to the grapheme $<$h$>$ in initial position in Portuguese, especially in
cognate words such as ‘hyper’, ‘hydrant’ and ‘hydrogen’.

The third process chosen was only changing [aj] to [i] while keeping the
pronunciation of initial [h] in words beginning with $<$hy$>$ (henceforth,
HY-hi). The HY-hi process goes in the opposite direction of the previous ones
concerning the pronunciation of $<$h$>$. In H-deletion and HY-i processes,
there is the deletion of initial [h], but in HY-hi the [h] is pronounced, with
only a replacement of [aj] by [i], as described above.

The fourth process investigated is the pronunciation of silent $<$k$>$ with the
insertion an epenthetic [i] in words beginning with $<$kn$>$ (henceforth,
KN-kin). This transfer process is characterized by the pronunciation of [k]
when $<$k$>$ should be silent in words like ‘knife’ or ‘knickers’.

The last process investigated was the voicing of /s/ when $<$s$>$ occurs
between two vowels (henceforth, S-z). It is the pronunciation of voiced [z]
when it should be voiceless [s]. The voicingoccurs in words like ‘basic’,
‘case’ or ‘fantasy’.

After the corpus selection, the speech collection took place on the Google
Translate™ online platform. The Text-to-Speech (TTS) system embedded on the
platform has the goal of generating a naturally-sounding speech waveform given
a text to be synthesized. This process of mapping a sequence of discrete
symbols (text) to a real-valued time series (waveform) is design to mimic the
human speech production, emulating the periodic and aperiodic components
present in human voice.

Recent researchers at Google have proposed the use of neural networks to
perform the mapping between linguistic features and acoustic features
\citep{tokuda_directly_2016, zen_fast_2016-1}. In 2017, about 1/3 of all
languages in Google’s TTS options already used Recurrent Neural Networks (RNN)
as acoustic models and almost all options of languages in Android mobile
devices already used RNN-based TTS systems \citep{zen_generative_2017-1}. The
mapping of linguistic features to acoustic features using a
parallel-distributed system is remarkably similar to the human reading process
in the brain.

To collect the samples produced by Google Translate™, we used the open-source
audio software Audacity (version 2.1.2). All the data in this research were
collected in August of 2018. The productions were recorded at 44.1 kHz
(standard) in Wave 32-bit float PCM. However, raw speech contains thousands of
samples, which are often polluted with noise and unnecessary information. The
solution is to convert the audio signal into a format with higher information
density. To obtain these dense representations, we opted to use the PRAAT
software (version 6.0.21).

To test different types of representation, we chose two descriptors: the mean
of Formant Frequency (FF) and the mean of the Fundamental Frequency
($\textit{f}_0$). The PRAAT software presents the oscillogram and spectrogram
of audio files. This way, it is possible to select, in each word, the exact
region where each researched phenomenon occurred. This specific region was
selected, cut, and saved in Wave format, resulting in a file referring to the
exclusive region of incidence of transfer processes. The objective was to
extract both $\textit{f}_0$ mean and the mean of F1 and F2 from the selected
region. Although two different methods are used to obtain these values, the
same audio file was used for both extractions.

\section{RBF Neural Network}
An artificial neural network is a system composed of ordered neurons in layers
interconnected through synaptic weights. These synaptic weights ponder the
connection between two neurons, or between an input and a neuron, assuming a
higher value according to the influence of that connection to the output of the
network. ANN has input nodes that receive stimuli from the external medium and
output neurons that provide the network response. Usually, a layer between the
input and output neurons is used, known as the hidden layer. The use of the
hidden layer structure enables ANN to solve non-linearly separable problems.

A Radial Basis Function Artificial Neural Network is a three-layer feed-forward
network that consists of one input layer, responsible for receiving the inputs,
one middle layer, fully connectedto the input layer, and one output layer, also
fully connected by weighted synapses and responsible for outputting the neural
network prediction. Each input neuron corresponds to a component ofon input
vector (in this case F1, F2 and $\textit{f}_0$). The middle layer consists of N
neurons and one bias neuron. Each middle neuron layer neuron computes a kernel
function which is usuallythe Gaussian function \citep{HWANG19971495}.

In order to specify the middle layer of an RBF-ANN we have to decide the number
of neurons in the kernel layer. The simplest method is creating one neuron for
each category present in the data.However, this method is not a good practice
for most applications and can be sub-optimal, especially when there is a large
number of training patterns. Therefore, we used a K-means algorithm tocluster
the training patterns in a reasonable number of groups. K-means is a kind of
unsupervised clustering algorithm that search internal groups in the dataset,
clustering the samples that belong to the same group enabling the adjustment of
the centers and radius of the Gaussian kernels in the hidden layer
\citep{chang_2010}.

Next, we use the standard statistical approach to calculate the weights between
the middle layer and the output layer. The Least Mean Square Error (LMSE)
procedure was used to determine the weights for each synaptic connection
between the layers. This method finds the parameters of a linear function by
the principle of Least Squares: minimizing the sum of the square of the
differencesbetween the observed dependent variable and those predicted by the
linear function of the independent variable. In our case, the independent
variable is the vector of desired outputs, and the dependent variable is the
vector of outputs of the hidden layer. The algorithm finds the linear
relationship between these variables (hidden weights) using a nonlinear
transformation.

As the neural networks are supervised algorithms, we manually classified the
datasets and divided into a training subset (or memory subset) and a testing
subset. The training subset is used as reference to the algorithm, presenting
enough information about the behavior of the samples to allow for learning and
generalization. With the training process completed, the neural network was
tested with the testing subset. The samples of the training subset were never
presented during the testing process or added in the reference data. This way
we could test the accuracy and generalization levels of the model for new
samples.

\section{Results and Discussion}
In summary, the results correspond to the average accuracy for each of the 50
iterations using randomized holdout for training, cross-validation and testing
subsets. The average accuracy ± standard deviation obtained by the algorithm in
each phenomenon is distributed in Table \ref{tab-atos}, presenting the
performance in the test sets using both mean $\textit{f}_0$ and the mean of the
first two FF. We also displayed the optimal number of hidden neurons found by
the K-means algorithm.

\begin{table*}[h]
\caption{Accuracy obtained by the RBF-ANN in each phenomenon studied.}\label{tab-atos}
\centering
\begin{tabular}{c|cccc}
\hline
\multirow{2}{*}{Results} & \multicolumn{4}{c}{Processes} \\
\cline{2-5}  & H-deletion & HY-i/HY-hi  & KN-kin  & S-z  \\
\hline
Accuracy & \textbf{0.9203 $\pm$ 0.0234} & \textbf{0.9445 $\pm$ 0.0958} & \textbf{0.9441 $\pm$ 0.0368} & \textbf{0.9308 $\pm$ 0.0223}  \\
\hline
Kernels  & 6  & 2  & 2  & 2 \\
\hline
\end{tabular}
\end{table*}

The results presented by the RBF-ANN algorithm were in general satisfactory for
the identification goal. The algorithm obtained high levels of accuracy for all
the phenomena with small variability on the results for the 50 iterations,
providing a promising perspective for the development of a new
computer-assisted pronunciation training software.

The number of kernels on the hidden layer found by K-means were expected for
all process except for H-deletion. One explanation for the higher number of
hidden units might be the existences of small clusters on the dataset. These
clusters do not only separate the native-like and phenomenon samples, but also
reveal internal structures inside the classes. Although these internal clusters
are not directly being used to separate the classes globally, they can be used
to enhance the accuracy of the decision boundary at the regions of
superposition between the classes.

\section{Conclusions}
After the evidence presented by the results, a series of conclusions about the
initial hypotheses could be drawn. The results indicated that RBF-ANN can
identify the transfer processes producedby the TTS algorithm using the audio
descriptor with high levels of accuracy and precision, providing ways to
automatically identify the five processes with confidence. The algorithm can be
trained with relatively small datasets, and it does not require huge
computational power to be trained. These results provided a new perspective on
the development of CAPT systems, demonstrating the advantages of using the
already developed literature about the transfer phenomena to make the
identification process more focused on the transfer patterns. This more
efficient approach can be implemented on devices with limited processing power,
such as mobile devices and online applications.

For future works, it is still necessary to expand the investigation with more
phenomena and to acquire a greater number of samples for each process
investigated. Expanding the number samples and testing new phenomena will
provide new information for the development of a simple and efficient
identification software. Further investigation can provide significant new
information and ideas not only for software development but also about the
phenomena themselves.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plainnat}
\bibliography{atosapollosil18.bib}

